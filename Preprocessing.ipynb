{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import ast\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "image = Image.open('data_raw/sb-sprite-uhr-k.png')\n",
    "my_dict = dict()\n",
    "for b in range(0, 397, 36):\n",
    "    for a in range(0, 325, 36):\n",
    "        text = pytesseract.image_to_string(image.crop((a+5, b+5, a+36-5, b+36-5)), config='--psm 6')\n",
    "        my_dict.update({f\"background-position: -{a}px -{b}px\" : text})\n",
    "\n",
    "with open('data_raw/sb-sprite-uhr-k.json', 'a') as f:\n",
    "    json.dump(my_dict, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update time column\n",
    "with open('data_raw/sb-sprite-uhr-k.json', 'r') as f:\n",
    "    my_dict = json.load(f)\n",
    "\n",
    "with open('data_raw/merge.csv', 'r', encoding='utf-8') as f:\n",
    "    data = pd.read_csv(f)\n",
    "    for index, row in data.iterrows():\n",
    "        row_list = ast.literal_eval(row['time'])\n",
    "        row_list_1 = row_list[0]\n",
    "        row_list_2 = row_list[1]\n",
    "        # print(row_list)\n",
    "        for i, time in enumerate(row_list_1):\n",
    "            if row_list_1[i] in my_dict:\n",
    "                row_list_1[i] = my_dict[row_list_1[i]]\n",
    "        for i, time in enumerate(row_list_2):\n",
    "            if row_list_2[i] in my_dict:\n",
    "                row_list_2[i] = my_dict[row_list_2[i]]\n",
    "        row_list = [row_list_1, row_list_2]\n",
    "        data.at[index, 'time'] = row_list\n",
    "\n",
    "with open('data_raw/output_data_0.csv', 'w', encoding='utf-8') as f:\n",
    "    data.to_csv(f, index=False, lineterminator='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get data from combined_data.csv\n",
    "with open('data_raw/output_data_filled.csv', 'r', encoding='utf-8') as f:\n",
    "    data = pd.read_csv(f)\n",
    "\n",
    "# Convert string elements to lists\n",
    "data['home_goals'] = data['home_goals'].apply(ast.literal_eval)\n",
    "data['home_substitution'] = data['home_substitution'].apply(ast.literal_eval)\n",
    "data['home_card'] = data['home_card'].apply(ast.literal_eval)\n",
    "data['time'] = data['time'].apply(ast.literal_eval)\n",
    "data['away_goals'] = data['away_goals'].apply(ast.literal_eval)\n",
    "data['away_substitution'] = data['away_substitution'].apply(ast.literal_eval)\n",
    "data['away_card'] = data['away_card'].apply(ast.literal_eval)\n",
    "\n",
    "# Iterate through each row to add the corresponding time to events\n",
    "for index, row in data.iterrows():\n",
    "    j = k = 0\n",
    "    for i, time in enumerate(row['time'][0]):\n",
    "        if i < len(row['home_goals']):\n",
    "            row['home_goals'][i] = [time, row['home_goals'][i]]\n",
    "        elif j < len(row['home_substitution']):\n",
    "            row['home_substitution'][j] = [time, row['home_substitution'][j]]\n",
    "            j += 1\n",
    "        elif k < len(row['home_card']):\n",
    "            row['home_card'][k] = [time, row['home_card'][k]]\n",
    "            k += 1\n",
    "\n",
    "    j = k = 0\n",
    "    for i, time in enumerate(row['time'][1]):\n",
    "        if i < len(row['away_goals']):\n",
    "            row['away_goals'][i] = [time, row['away_goals'][i]]\n",
    "        elif j < len(row['away_substitution']):\n",
    "            row['away_substitution'][j] = [time, row['away_substitution'][j]]\n",
    "            j += 1\n",
    "        elif k < len(row['away_card']):\n",
    "            row['away_card'][k] = [time, row['away_card'][k]]\n",
    "            k += 1\n",
    "\n",
    "# # Add ID column\n",
    "# data['ID'] = range(1, len(data) + 1)\n",
    "\n",
    "# Save the data just with ID, time, home_goals, home_substitution, home_card, away_goals, away_substitution, away_card\n",
    "# data = data[['ID', 'time', 'home_goals', 'home_substitution', 'home_card', 'away_goals', 'away_substitution', 'away_card']]\n",
    "with open('data_raw/output_data_filled.csv', 'w', encoding='utf-8') as f:\n",
    "    data.to_csv(f, index=False, lineterminator='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get starting_lineup from output_data_2.csv\n",
    "with open('data_raw/output_data_5.csv', 'r', encoding='utf-8') as f:\n",
    "    data = pd.read_csv(f)\n",
    "\n",
    "# Handle NaN values and convert string elements (starting_lineup) to lists\n",
    "data['starting_lineup'] = data['starting_lineup'].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "\n",
    "# Iterate through each row to extract and add the new columns\n",
    "for index, row in data.iterrows():\n",
    "    if row['starting_lineup']:\n",
    "        sample_string = row['starting_lineup']\n",
    "        avg_age = float(re.search(r'Avg\\. age: (\\d+\\.\\d+)', sample_string[33]).group(1))\n",
    "        purchase_value = float(re.search(r'Purchase value: €(\\d+\\.\\d+)', sample_string[33]).group(1))\n",
    "        total_mv = float(re.search(r'Total MV: €(\\d+\\.\\d+)', sample_string[33]).group(1))\n",
    "        data.at[index, 'home_avg_age'] = avg_age\n",
    "        data.at[index, 'home_purchase_value'] = purchase_value\n",
    "        data.at[index, 'home_total_mv'] = total_mv\n",
    "\n",
    "# Save the  data just with 4 columns ID, home_avg_age, home_purchase_value, home_total_mv\n",
    "data = data[['ID', 'home_avg_age', 'home_purchase_value', 'home_total_mv']]\n",
    "with open('data_raw/output_data_6.csv', 'w', encoding='utf-8') as f:\n",
    "    data.to_csv(f, index=False, lineterminator='\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from output_data_3.csv\n",
    "with open('data_raw/output_data_3.csv', 'r', encoding='utf-8') as f:\n",
    "    data = pd.read_csv(f)\n",
    "\n",
    "# Remove the first column, year and add the new columns ID at the start, and add year at the end\n",
    "data = data.drop(columns=['Unnamed: 0'])\n",
    "data = data.drop(columns=['year'])\n",
    "data.insert(0, 'ID', range(1, 1 + len(data)))\n",
    "\n",
    "# Convert string elements (date_time) to lists\n",
    "data['date_time'] = data['date_time'].apply(ast.literal_eval)\n",
    "# Create a new column (year)\n",
    "data['year'] = data['date_time'].apply(lambda x: '20' + str(x[1].split('/')[-1]))\n",
    "\n",
    "# Save the updated data\n",
    "with open('data_raw/output_data_4.csv', 'w', encoding='utf-8') as f:\n",
    "    data.to_csv(f, index=False, lineterminator='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from output_data_4.csv\n",
    "with open('data_raw/output_data_5.csv', 'r', encoding='utf-8') as f:\n",
    "    data = pd.read_csv(f)\n",
    "\n",
    "# Convert string elements from stat column to lists\n",
    "data['stat'] = data['stat'].apply(ast.literal_eval)\n",
    "\n",
    "# Creat a loop to get the value from stat column and add it to the new columns\n",
    "for index, row in data.iterrows():\n",
    "    if row['stat']:\n",
    "        data.at[index, 'Total_shots_home'] = row['stat'][1].split()[0]\n",
    "        data.at[index, 'Total_shots_away'] = row['stat'][1].split()[1]\n",
    "        data.at[index, 'Shots_off_home'] = row['stat'][2].split()[0]\n",
    "        data.at[index, 'Shots_off_away'] = row['stat'][2].split()[1]\n",
    "        data.at[index, 'Shots_saved_home'] = row['stat'][3].split()[0]\n",
    "        data.at[index, 'Shots_saved_away'] = row['stat'][3].split()[1]\n",
    "        data.at[index, 'Corners_home'] = row['stat'][4].split()[0]\n",
    "        data.at[index, 'Corners_away'] = row['stat'][4].split()[1]\n",
    "        data.at[index, 'Free_kicks_home'] = row['stat'][5].split()[0]\n",
    "        data.at[index, 'Free_kicks_away'] = row['stat'][5].split()[1]\n",
    "        data.at[index, 'Fouls_home'] = row['stat'][6].split()[0]\n",
    "        data.at[index, 'Fouls_away'] = row['stat'][6].split()[1]\n",
    "        data.at[index, 'Off_sides_home'] = row['stat'][7].split()[0]\n",
    "        data.at[index, 'Off_sides_away'] = row['stat'][7].split()[1]\n",
    "\n",
    "# Save the  data just with 4 columns ID, Total_shots_home, Total_shots_away, Shots_off_home, Shots_off_away, Shots_saved_home, Shots_saved_away, Corners_home, Corners_shots_away, Free_kicks_home, Free_kicks_away, Fouls_home, Fouls_away, Off_sides_home, Off_sides_away\n",
    "data = data[['ID', 'Total_shots_home', 'Total_shots_away', 'Shots_off_home', 'Shots_off_away', 'Shots_saved_home', 'Shots_saved_away', 'Corners_home', 'Corners_away', 'Free_kicks_home', 'Free_kicks_away', 'Fouls_home', 'Fouls_away', 'Off_sides_home', 'Off_sides_away']]\n",
    "with open('data_raw/output_data_7.csv', 'w', encoding='utf-8') as f:\n",
    "    data.to_csv(f, index=False, lineterminator='\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from output_data_5.csv\n",
    "with open('data_raw/output_data_1.csv', 'r', encoding='utf-8') as f:\n",
    "    data = pd.read_csv(f)\n",
    "\n",
    "# Convert string elements to lists\n",
    "data['home_card'] = data['home_card'].apply(ast.literal_eval)\n",
    "data['away_card'] = data['away_card'].apply(ast.literal_eval)\n",
    "\n",
    "# # Show home_card column\n",
    "# print(data['home_card'][0])\n",
    "# print(data['home_card'][1])\n",
    "# print(data['home_card'][14])\n",
    "\n",
    "# Initialize new columns\n",
    "data['home_number_of_yellow_card'] = 0\n",
    "data['home_number_of_red_card'] = 0\n",
    "data['away_number_of_yellow_card'] = 0\n",
    "data['away_number_of_red_card'] = 0\n",
    "\n",
    "# Function to count yellow and red cards\n",
    "def count_cards(card_list):\n",
    "    if not card_list or card_list == [[]]:\n",
    "        return 0, 0\n",
    "    yellow_cards = sum('Yellow card' in (card[1] or '') for card in card_list if card)\n",
    "    red_cards = sum('Red card' in (card[1] or '') for card in card_list if card)\n",
    "    return yellow_cards, red_cards\n",
    "\n",
    "# Iterate through each row to count the number of yellow and red cards\n",
    "for index, row in data.iterrows():\n",
    "    home_yellow, home_red = count_cards(row['home_card'])\n",
    "    away_yellow, away_red = count_cards(row['away_card'])\n",
    "    \n",
    "    data.at[index, 'home_number_of_yellow_card'] = home_yellow\n",
    "    data.at[index, 'home_number_of_red_card'] = home_red\n",
    "    data.at[index, 'away_number_of_yellow_card'] = away_yellow\n",
    "    data.at[index, 'away_number_of_red_card'] = away_red\n",
    "\n",
    "# Save the updated data\n",
    "data = data[['ID', 'home_number_of_yellow_card', 'home_number_of_red_card', 'away_number_of_yellow_card', 'away_number_of_red_card']]\n",
    "with open('data_raw/output_data_9.csv', 'w', encoding='utf-8') as f:\n",
    "    data.to_csv(f, index=False, lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                        0\n",
      "date_time                 0\n",
      "stadium                   0\n",
      "home_team                 0\n",
      "home_position             0\n",
      "away_team                 0\n",
      "away_position             0\n",
      "score                     0\n",
      "referee                   0\n",
      "time                      0\n",
      "home_lineup               0\n",
      "away_lineup               0\n",
      "home_squads               0\n",
      "away_squads               0\n",
      "home_substitute           0\n",
      "away_substitute           0\n",
      "home_goals                0\n",
      "away_goals                0\n",
      "home_substitution         0\n",
      "away_substitution         0\n",
      "home_card                 0\n",
      "away_card                 0\n",
      "home_sanctions            0\n",
      "away_sanctions            0\n",
      "starting_lineup           0\n",
      "substitute               11\n",
      "manager                  11\n",
      "stat                      0\n",
      "url                       0\n",
      "avg_age                  11\n",
      "purchase_value           11\n",
      "total_mv                 11\n",
      "year                      0\n",
      "shots_home              248\n",
      "shots_away              248\n",
      "shots_on_target_home    248\n",
      "shots_on_target_away    248\n",
      "corners_home            248\n",
      "corners_away            248\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count None values in data\n",
    "with open('data_raw/output_data_5.csv', 'r', encoding='utf-8') as f:\n",
    "    data = pd.read_csv(f)\n",
    "    print(data.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                      0\n",
      "date_time               0\n",
      "stadium                 0\n",
      "home_team               0\n",
      "home_position           0\n",
      "away_team               0\n",
      "away_position           0\n",
      "score                   0\n",
      "referee                 0\n",
      "time                    0\n",
      "home_lineup             0\n",
      "away_lineup             0\n",
      "home_squads             0\n",
      "away_squads             0\n",
      "home_substitute         0\n",
      "away_substitute         0\n",
      "home_goals              0\n",
      "away_goals              0\n",
      "home_substitution       0\n",
      "away_substitution       0\n",
      "home_card               0\n",
      "away_card               0\n",
      "home_sanctions          0\n",
      "away_sanctions          0\n",
      "starting_lineup         0\n",
      "substitute              0\n",
      "manager                 0\n",
      "stat                    0\n",
      "url                     0\n",
      "avg_age                 0\n",
      "purchase_value          0\n",
      "total_mv                0\n",
      "year                    0\n",
      "shots_home              0\n",
      "shots_away              0\n",
      "shots_on_target_home    0\n",
      "shots_on_target_away    0\n",
      "corners_home            0\n",
      "corners_away            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fill missing values based on the previous match information of the same team\n",
    "def fill_missing_values(data):\n",
    "    columns_to_fill = ['manager', 'substitute', 'avg_age', 'purchase_value', 'total_mv', 'shots_home', 'shots_away', 'shots_on_target_home', 'shots_on_target_away', 'corners_home', 'corners_away']\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        if any(pd.isnull(row[col]) for col in columns_to_fill):\n",
    "            home_team = row['home_team']\n",
    "            away_team = row['away_team']\n",
    "            \n",
    "            # Find the previous match where the home_team or away_team is the same\n",
    "            previous_match = data.loc[(data.index < index) & ((data['home_team'] == home_team) | (data['away_team'] == home_team) | (data['home_team'] == away_team) | (data['away_team'] == away_team))].tail(1)\n",
    "            \n",
    "            if not previous_match.empty:\n",
    "                previous_row = previous_match.iloc[0]\n",
    "                \n",
    "                # Fill missing values based on the previous match\n",
    "                for column in columns_to_fill:\n",
    "                    if pd.isnull(row[column]):\n",
    "                        data.at[index, column] = previous_row[column]\n",
    "    return data\n",
    "\n",
    "# Apply the function to fill missing values\n",
    "data = fill_missing_values(data)\n",
    "\n",
    "# Show the number of missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Save the updated data\n",
    "with open('data_raw/output_data_filled.csv', 'w', encoding='utf-8') as f:\n",
    "    data.to_csv(f, index=False, lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first row\n",
    "first_row_df = data.iloc[0]\n",
    "\n",
    "# Add a new column with information\n",
    "first_row_df['Information'] = ['ID', 'date_time', 'stadium', 'home_team', 'home_position', 'away_team', 'away_position', 'score', 'referee', 'time', 'home_lineup', 'away_lineup', 'home_squads', 'away_squads', 'home_substitute', 'away_substitute', 'home_goals', 'away_goals', 'home_substitution', 'away_substitution', 'home_card', 'away_card', 'home_sanctions', 'away_sanctions', 'starting_lineup', 'substitute', 'manager', 'stat', 'url', 'avg_age', 'purchase_value', 'total_mv', 'year', 'shots_home', 'shots_away', 'shots_on_target_home', 'shots_on_target_away', 'corners_home', 'corners_away']\n",
    "\n",
    "# Ensure 'Value' column exists\n",
    "first_row_df['Value'] = first_row_df.values\n",
    "\n",
    "# Reorder columns to have 'Information' first\n",
    "first_row_df = first_row_df[['Information', 'Value']]\n",
    "\n",
    "# Display the result\n",
    "print(first_row_df)\n",
    "\n",
    "# Save the first row to a CSV file\n",
    "with open('data_raw/first_row.csv', 'w', encoding='utf-8') as f:\n",
    "    first_row_df.to_csv(f, index=False, lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      lineup_id_away      away_lineup\n",
      "0                  0          4-2-3-1\n",
      "2                  1            3-5-2\n",
      "3                  2   4-4-2 double 6\n",
      "5                  3          4-1-4-1\n",
      "11                 4  4-3-3 Attacking\n",
      "13                 5            4-4-2\n",
      "15                 6          4-4-1-1\n",
      "17                 7       3-5-2 flat\n",
      "18                 8            5-4-1\n",
      "20                 9          3-1-4-2\n",
      "22                10  4-3-3 Defending\n",
      "33                11    4-4-2 Diamond\n",
      "34                12          3-4-2-1\n",
      "36                13          4-3-1-2\n",
      "70                14       4-5-1 flat\n",
      "105               15            5-3-2\n",
      "237               16    5-4-1 Diamond\n",
      "442               17          4-3-2-1\n",
      "786               18            3-4-3\n",
      "914               19            4-5-1\n",
      "971               20          3-4-1-2\n",
      "1568              21          4-1-3-2\n",
      "2605              22  3-5-2 Attacking\n",
      "2632              23          3-3-3-1\n"
     ]
    }
   ],
   "source": [
    "# Load the data from data_train.csv\n",
    "data_train = pd.read_csv('data_raw/data_train.csv')\n",
    "\n",
    "# Extract the distinct values of team_id_away and away_team\n",
    "distinct_values = data_train[['lineup_id_away', 'away_lineup']].drop_duplicates()\n",
    "\n",
    "# Display the distinct values\n",
    "print(distinct_values)\n",
    "\n",
    "distinct_values.to_csv('data_raw/lineupID.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the timeID.csv file\n",
    "time_id_df = pd.read_csv('data_raw/timeID.csv')\n",
    "team_data = pd.read_csv('data_raw/team_data.csv')\n",
    "\n",
    "# Create a dictionary to map team names to their IDs\n",
    "team_name_to_id = dict(zip(time_id_df['team_name'], time_id_df['team_id']))\n",
    "\n",
    "# Map the team names to their IDs in the data_train DataFrame\n",
    "team_data['team_id'] = team_data['team_id'].map(team_name_to_id)\n",
    "\n",
    "# Save the updated data_train DataFrame to a new CSV file\n",
    "team_data.to_csv('data_raw/team_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data = pd.read_csv('data_raw/team_data.csv')\n",
    "# Convert string elements (date_time) to lists\n",
    "team_data['date_time'] = team_data['date_time'].apply(ast.literal_eval)\n",
    "\n",
    "# Extract year, month, and day from date_time\n",
    "team_data['year'] = team_data['date_time'].apply(lambda x: '20' + str(x[1].split('/')[-1].split(' ')[0]))\n",
    "team_data['month'] = team_data['date_time'].apply(lambda x: str(x[1].split('/')[0].split(' ')[-1]))\n",
    "team_data['day'] = team_data['date_time'].apply(lambda x: str(x[1].split('/')[1]))\n",
    "\n",
    "# Save the updated data\n",
    "with open('data_raw/team_data.csv', 'w', encoding='utf-8') as f:\n",
    "    team_data.to_csv(f, index=False, lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with null values in team_data\n",
    "team_data = team_data.dropna()\n",
    "\n",
    "# Save the updated data\n",
    "with open('data_raw/team_data.csv', 'w', encoding='utf-8') as f:\n",
    "    team_data.to_csv(f, index=False, lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the date_time column\n",
    "# team_data = team_data.drop(columns=['date_time'])\n",
    "# Convert all numeric columns to integers\n",
    "numeric_columns = team_data.select_dtypes(include=['float64']).columns\n",
    "team_data[numeric_columns] = team_data[numeric_columns].astype(int)\n",
    "\n",
    "# Save the updated data\n",
    "with open('data_raw/team_data.csv', 'w', encoding='utf-8') as f:\n",
    "    team_data.to_csv(f, index=False, lineterminator='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      team_id  Total_shots  Shots_off  Shots_saved  Corners  Free_kicks  \\\n",
      "5           2            6          4            2        4          11   \n",
      "14          2            5          5            1        4          21   \n",
      "41          2            1          3            3        6           9   \n",
      "70          2            9          4            0        3           9   \n",
      "97          2            7          3            0        4          15   \n",
      "...       ...          ...        ...          ...      ...         ...   \n",
      "6968        2           17          5            5        9           6   \n",
      "6993        2            7          2            6        2          12   \n",
      "7006        2           27          8            6        6          10   \n",
      "7018        2           14          6            5        4           6   \n",
      "7041        2           11          2            2        5          10   \n",
      "\n",
      "      Off_sides  Fouls  year  month  day  \n",
      "5             1     15  2014      8   24  \n",
      "14            1     13  2014      8   16  \n",
      "41            2     13  2014      8   30  \n",
      "70            0     11  2014      9   14  \n",
      "97            4      7  2014      9   21  \n",
      "...         ...    ...   ...    ...  ...  \n",
      "6968          1     16  2024      5   15  \n",
      "6993          1      8  2024      5    6  \n",
      "7006          0      7  2024      4   27  \n",
      "7018          2      5  2024      5   12  \n",
      "7041          1      9  2024      5   19  \n",
      "\n",
      "[358 rows x 11 columns]\n",
      "     team_id  Total_shots  Shots_off  Shots_saved  Corners  Free_kicks  \\\n",
      "0          2            5          5            1        4          21   \n",
      "1          2            6          4            2        4          11   \n",
      "2          2            1          3            3        6           9   \n",
      "3          2            9          4            0        3           9   \n",
      "4          2            7          3            0        4          15   \n",
      "..       ...          ...        ...          ...      ...         ...   \n",
      "353        2           27          8            6        6          10   \n",
      "354        2            7          2            6        2          12   \n",
      "355        2           14          6            5        4           6   \n",
      "356        2           17          5            5        9           6   \n",
      "357        2           11          2            2        5          10   \n",
      "\n",
      "     Off_sides  Fouls  year  month  day  index  \n",
      "0            1     13  2014      8   16      0  \n",
      "1            1     15  2014      8   24      1  \n",
      "2            2     13  2014      8   30      2  \n",
      "3            0     11  2014      9   14      3  \n",
      "4            4      7  2014      9   21      4  \n",
      "..         ...    ...   ...    ...  ...    ...  \n",
      "353          0      7  2024      4   27    353  \n",
      "354          1      8  2024      5    6    354  \n",
      "355          2      5  2024      5   12    355  \n",
      "356          1     16  2024      5   15    356  \n",
      "357          1      9  2024      5   19    357  \n",
      "\n",
      "[358 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the team_data.csv file\n",
    "team_data = pd.read_csv('data_raw/team_data.csv')\n",
    "\n",
    "# Filter the data for team_id = 2\n",
    "team_data_filtered = team_data[team_data['team_id'] == 2]\n",
    "\n",
    "# Display the filtered data\n",
    "print(team_data_filtered)\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "team_data_filtered.to_csv('data_raw/team_data_filtered.csv', index=False)\n",
    "\n",
    "# Sort the data based on year, month, and day\n",
    "team_data_filtered = team_data_filtered.sort_values(by=['year', 'month', 'day'])\n",
    "\n",
    "# Add an index column\n",
    "team_data_filtered.reset_index(drop=True, inplace=True)\n",
    "team_data_filtered['index'] = team_data_filtered.index\n",
    "\n",
    "# Display the sorted and indexed data\n",
    "print(team_data_filtered)\n",
    "\n",
    "# Save the sorted and indexed data to a new CSV file\n",
    "team_data_filtered.to_csv('data_raw/team_data_filtered_sorted.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
